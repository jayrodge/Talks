# Classifying AudioMNIST (Dataset) usign PyTorch

## Description
This talk was delivered at [Chicago ML](chicago.ml) [Meetup](https://www.meetup.com/Chicago-ML/events/258768721/)

In this talk, I gave an overview on PyTorch 1.0, a deep learning framework.

Later, I also showed a demo for Classification of Audio Signals using Deep Neural Networks on the [AudioMNIST Dataset](https://github.com/soerenab/AudioMNIST)

The audio files from AudioMNIST dataset were converted into Spectrograms (Image representing change in frequency in Audio using Fourier transform through heatmaps), and then used these images as training data, to train Convolutional Neural Network, which gives an accuracy of 99% which beats the state of the art model.

## Code
The code for this project can be found in this [IPython Notebook](https://github.com/jayrodge/AudioMNIST-using-PyTorch/blob/master/AudioClassifierMNIST.ipynb)/Repository(https://github.com/jayrodge/AudioMNIST-using-PyTorch/)